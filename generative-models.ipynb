{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchinfo\n",
    "import skimage\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "EPOCHS = 10#0\n",
    "BATCH_SIZE = 256\n",
    "LR = 2e-4\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "  def __init__(self, X, Y):\n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.first_conv2d = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "    self.second_conv2d = torch.nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "    self.first_batchnorm2d = torch.nn.BatchNorm2d(64)\n",
    "    self.second_batchnorm2d = torch.nn.BatchNorm2d(64)\n",
    "    self.leakyrelu = torch.nn.LeakyReLU(0.2)\n",
    "    self.flatten = torch.nn.Flatten()\n",
    "    self.linear = torch.nn.Linear(3136, 1)\n",
    "    self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.first_conv2d(x)\n",
    "    x = self.first_batchnorm2d(x)\n",
    "    x = self.leakyrelu(x)\n",
    "    x = self.second_conv2d(x)\n",
    "    x = self.second_batchnorm2d(x)\n",
    "    x = self.leakyrelu(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.linear(x)\n",
    "    x = self.sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.linear = torch.nn.Linear(100, 6272)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "    self.first_convtranspose2d = torch.nn.ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
    "    self.second_convtranspose2d = torch.nn.ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
    "    self.first_batchnorm2d = torch.nn.BatchNorm2d(128)\n",
    "    self.second_batchnorm2d = torch.nn.BatchNorm2d(128)\n",
    "    self.conv2d = torch.nn.Conv2d(128, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
    "    self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.linear(x)\n",
    "    x = self.relu(x)\n",
    "    x = torch.reshape(x, (-1, 128, 7, 7))\n",
    "    x = self.first_convtranspose2d(x)\n",
    "    x = self.first_batchnorm2d(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.second_convtranspose2d(x)\n",
    "    x = self.second_batchnorm2d(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv2d(x)\n",
    "    x = self.sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, title, cmap=\"viridis\"):\n",
    "  plt.imshow(image, cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_image(image):\n",
    "  image = image / 255\n",
    "  image[image > 1] = 1\n",
    "  image[image < 0] = 0\n",
    "  image = image.astype(np.float32)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(images):\n",
    "  images = images[..., np.newaxis]\n",
    "  images = images.transpose((0, 3, 1, 2))\n",
    "\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_info(images, labels):\n",
    "  print(\"==================================\")\n",
    "  print(\"PODATKI O ZBIRKI SLIK\")\n",
    "  print(\"==================================\")\n",
    "  print(\"IME ZBIRKE: MNIST\")\n",
    "  print(f\"ŠTEVILO SLIK: {images.shape[0]}\")\n",
    "  print(f\"ŠIRINA SLIK: {images.shape[1]}\")\n",
    "  print(f\"VIŠINA SLIK: {images.shape[2]}\")\n",
    "  print(\"ŠTEVILO KANALOV SLIK: 1\")\n",
    "  print(\"PRIMERI SLIK:\")\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(images[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(labels[i])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "  print(\"==================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminator, generator, images):\n",
    "  discriminator = discriminator.to(device)\n",
    "  generator = generator.to(device)\n",
    "\n",
    "  discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=LR)\n",
    "  generator_optimizer = torch.optim.Adam(generator.parameters(), lr=LR)\n",
    "\n",
    "  discriminator_loss_fn = torch.nn.BCELoss()\n",
    "  generator_loss_fn = torch.nn.BCELoss()\n",
    "  \n",
    "  discriminator.train()\n",
    "  generator.train()\n",
    "      \n",
    "  dataset = ImageDataset(images, images)\n",
    "  dataloader = DataLoader(dataset=dataset, batch_size=int(BATCH_SIZE / 2), shuffle=True)\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    #if (epoch + 1) % 10 == 0:\n",
    "    print(f\"TRAINING EPOCH {epoch + 1} OF {EPOCHS}\")\n",
    "    \n",
    "    inputs = torch.from_numpy(np.random.normal(size=(int(BATCH_SIZE / 2), 100)).astype(np.float32)).to(device)\n",
    "    \n",
    "    for step, (input_batch, _) in enumerate(dataloader):\n",
    "      input_batch = input_batch.to(device)\n",
    "      first_target = torch.from_numpy(np.ones((int(BATCH_SIZE / 2), 1), dtype=np.float32)).to(device)\n",
    "      second_target = torch.from_numpy(np.zeros((int(BATCH_SIZE / 2), 1), dtype=np.float32)).to(device)\n",
    "\n",
    "      discriminator_optimizer.zero_grad()\n",
    "      pred = discriminator(input_batch)\n",
    "      loss = discriminator_loss_fn(pred, first_target)\n",
    "      loss.backward()\n",
    "\n",
    "      #inputs = torch.from_numpy(np.random.normal(size=(int(BATCH_SIZE / 2), 100)).astype(np.float32)).to(device)\n",
    "      outputs = generator(inputs)\n",
    "\n",
    "      pred = discriminator(outputs)\n",
    "      loss = discriminator_loss_fn(pred, second_target)\n",
    "      loss.backward()\n",
    "      \n",
    "      discriminator_optimizer.step()\n",
    "\n",
    "      generator_optimizer.zero_grad()\n",
    "      \n",
    "      #inputs = torch.from_numpy(np.random.normal(size=(int(BATCH_SIZE / 2), 100)).astype(np.float32)).to(device)\n",
    "      outputs = generator(inputs)\n",
    "\n",
    "      pred = discriminator(outputs)\n",
    "      loss = generator_loss_fn(pred, first_target)\n",
    "      loss.backward()\n",
    "\n",
    "      generator_optimizer.zero_grad()\n",
    "\n",
    "  torch.save(discriminator, f\"discriminator{EPOCHS}.pt\")\n",
    "  torch.save(generator, f\"generator{EPOCHS}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\"datasets\", download=True)\n",
    "\n",
    "images = np.array([fix_image(np.array(el[0])) for el in dataset])[:59904]\n",
    "labels = np.array([el[1] for el in dataset])[:25]\n",
    "\n",
    "print_dataset_info(images, labels)\n",
    "images = expand(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torchinfo.summary(discriminator, (128, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torchinfo.summary(generator, (1, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(discriminator, generator, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"generator10.pt\", map_location=device)\n",
    "inputs = torch.from_numpy(np.random.normal(size=(1, 100)).astype(np.float32)).to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = pred.cpu().detach().numpy()[0].transpose(1, 2, 0)\n",
    "\n",
    "print(np.min(pred))\n",
    "print(np.max(pred))\n",
    "\n",
    "display_image(pred, 'output', 'gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6532684ccaeb1bcbbe852b7f75c67e6f1d55df7d386020fd37670376cbe3d2c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
